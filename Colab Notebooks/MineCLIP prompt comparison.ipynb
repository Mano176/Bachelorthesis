{"cells":[{"cell_type":"markdown","metadata":{"id":"87oVFd-vqmte"},"source":["# Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_Lpi1Bgt08d"},"outputs":[],"source":["batch_size = 16\n","frame_height = 160\n","frame_width = 256\n","original_fps = 30\n","desired_fps = 30\n","pool_type = \"avg\"\n","assert desired_fps <= original_fps, \"desired_fps can't be higher than original_fps\"\n","assert pool_type == \"avg\" or pool_type == \"attn\", \"pool_type must be either avg or attn\""]},{"cell_type":"markdown","metadata":{"id":"RYezGJgLq7zc"},"source":["# Installing python packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilQMNOogMdjs"},"outputs":[],"source":["!pip install --upgrade importlib_resources==5.12.0 --quiet\n","!pip install --upgrade setuptools==65.4.1 --quiet\n","!pip install wheel==0.38.4 --quiet\n","!pip install av --quiet\n","!pip install git+https://github.com/MineDojo/MineCLIP --quiet"]},{"cell_type":"markdown","metadata":{"id":"3ZbFZUVaq3qm"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oDK_O7Hp3-cW"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as T\n","from torch.utils.data import Dataset, DataLoader\n","from mineclip import MineCLIP\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cu9A8OyHVOk"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd \"drive/MyDrive/MineCLIP_prompt_comparison\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGoSL2MDVS1M"},"outputs":[],"source":["class VideoDataset(Dataset):\n","\tdef __init__(self, data):\n","\t\tself.data = data\n","\n","\tdef __getitem__(self, index):\n","\t\tx = self.data[index]\n","\t\treturn x\n","\n","\tdef __len__(self):\n","\t\treturn len(self.data)"]},{"cell_type":"markdown","metadata":{"id":"9w6HIPJgrFJa"},"source":["# Initializing MineCLIP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YSMajwgi25n"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Running with\", device)\n","model = MineCLIP(\n","\tarch=\"vit_base_p16_fz.v2.t2\",\n","\tresolution=[frame_height, frame_width],\n","\tpool_type= \"avg\" if pool_type == \"avg\" else \"attn.d2.nh8.glusw\",\n","\timage_feature_dim=512,\n","\tmlp_adapter_spec=\"v0-2.t0\", # v3-1.t2\n","\thidden_dim=512\n",").to(device)\n","model.load_ckpt(f\"./{pool_type}.pth\")"]},{"cell_type":"markdown","metadata":{"id":"KPRtwE4lrIkd"},"source":["# Setting prompts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeUHr9Bsi58a"},"outputs":[],"source":["prompts = [\n","    np.array([\n","      \"approach tree\"\n","    ]), np.array([\n","      \"chop tree\",\n","      \"farm wood\",\n","      \"farm logs\"\n","    ]), np.array([\n","      \"craft wooden planks\",\n","      \"craft planks\",\n","      \"make wooden planks\",\n","      \"make planks\",\n","      \"craft planks out of the logs\"\n","    ]), np.array([\n","      \"craft a crafting table\",\n","      \"craft a workbench\",\n","      \"make a crafting table\",\n","      \"make a workbench\",\n","      \"craft a crafting table with 4 wood\"\n","    ]), np.array([\n","      \"place crafting table\",\n","      \"place workbench\"\n","    ]), np.array([\n","      \"craft sticks\",\n","      \"make sticks\",\n","      \"craft sticks with 2 wood\"\n","    ]), np.array([\n","      \"craft a wooden pickaxe\",\n","      \"craft a pickaxe\",\n","      \"make a wooden pickaxe\",\n","      \"craft a pickaxe with 2 sticks and 3 wood\"\n","    ]), np.array([\n","        \"use an anvil\",\n","        \"defeat the enderdragon\"\n","    ])\n","]\n","prompts_flattened = np.concatenate(np.array(prompts, dtype=object)).ravel().tolist()\n","prompt_feats = model.encode_text(prompts_flattened)"]},{"cell_type":"markdown","metadata":{"id":"Sd6qb-wOrLUu"},"source":["# Loading the video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJpFxIPki_q7"},"outputs":[],"source":["video_object = torchvision.io.VideoReader(\"./MC_Clip.mp4\", \"video\")\n","transform = T.Resize((frame_height, frame_width), antialias=False)\n","video_object.set_current_stream(\"video\")\n","frames = []\n","for i, frame in enumerate(video_object):\n","\tif i % int(original_fps/desired_fps) == 0:\n","\t\tframes.append(transform(frame['data']))\n","loader = DataLoader(\n","\tVideoDataset(torch.stack(frames, 0)),\n","\tbatch_size=batch_size,\n","\tshuffle=False\n",")\n","print(f\"Loaded video with {len(frames)} frames\")"]},{"cell_type":"markdown","metadata":{"id":"Vyk4IRlWrQBs"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jZa2DIJjHa-"},"outputs":[],"source":["rewards = []\n","max_scores = [-float(\"inf\")] * len(prompts_flattened)\n","best_batches = [None] * len(prompts_flattened)\n","batch_count = 1\n","for data in loader:\n","  print(f\"Evaluating batch {batch_count}/{round(len(frames)/batch_size+0.5)}\")\n","  data = torch.unsqueeze(data, dim=0).to(device)\n","  with torch.no_grad():\n","    reward, _ = model(data, text_tokens=prompt_feats, is_video_features=False)\n","  reward = reward[0]\n","  for i in range(len(prompts_flattened)):\n","    if max_scores[i] < reward[i]:\n","      max_scores[i] = reward[i].cpu()\n","      best_batches[i] = data.cpu()[0]\n","  rewards.append(reward.cpu().numpy())\n","  batch_count += 1"]},{"cell_type":"markdown","metadata":{"id":"o-PH_oe_rTnt"},"source":["# Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qT2OntU9nt82"},"outputs":[],"source":["rewards_reshaped = np.array(rewards).T\n","prompt_count = 0\n","for i, prompts_specific in enumerate(prompts):\n","  rewards_specific = rewards_reshaped[prompt_count:prompt_count+len(prompts_specific)].T\n","  plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n","  plt.xlabel(\"Batches\")\n","  plt.ylabel(\"Score\")\n","  plt.plot(rewards_specific)\n","  plt.legend(prompts_specific)\n","  plt.savefig(f\"plots/prompt_comparison_{i}.png\", bbox_inches=\"tight\")\n","  plt.show()\n","  prompt_count += len(prompts_specific)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ErBAmReqXBB"},"outputs":[],"source":["for i in range(len(prompts_flattened)):\n","  fig, axs = plt.subplots(1, batch_size, figsize=(frame_width, frame_height/batch_size))\n","  fig.suptitle(f\"batch with max score of {round(float(max_scores[i]), 2)} for prompt: \\\"{prompts_flattened[i]}\\\"\", fontsize=100)\n","  for j in range(batch_size):\n","    if j >= len(best_batches[i]):\n","      break\n","    axs[j].imshow(best_batches[i][j].permute(1, 2, 0))\n","  plt.savefig(f\"plots/best_batch_{i}.png\", bbox_inches=\"tight\")\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEhmjXnrdQX0"},"outputs":[],"source":["print(f\"average max-score for all tasks: {np.average(max_scores)}\")"]},{"cell_type":"markdown","metadata":{"id":"dXnQxt5Rmu-u"},"source":["# Results\n","\n","\n","*   Prompt \"chop tree\" performs a lot better than \"farm wood\" and \"farm logs\"\n","*   Phrase \"craft\" is better than \"make\"\n","*   Phrase \"crafting table\" is better than \"workbench\" (probably more used in training data because it is the official term)\n","*   Extra information on the recipe lead to higher scores\n","*   Scores for prompt \"use an anvil\" and \"defeat the enderdragon\" are only slightly lower than scores for other prompts, even though the agent could not complete the tasks\n","*   The prompt \"make a wooden pickaxe\" achieves highest score while looking at a tree, rather than actually crafting a wooden pickaxe (not everytime though)\n","*   Prompts for crafting an object sometimes achieve the highest score for looking at the finished object, rather than crafting it\n","* Prompts for crafting an object yield higher scores just when the inventory or the crafting table menu is open (and doesn't take into account what actually gets crafted)\n","*   Using lower FPS doesn't seem to have much of an impact on the scores (would probably be best to use FPS high enough so that there aren't too many different actions in one batch)\n","*   Pool types \"avg\" and \"attn\" seem to achieve similar relative results (but overall avg has lower scores). \"use an anvil\" and \"defeat the enderdragon\" prompt has lower scores with avg pool type though\n","*   All in all does the model a good job on detecting when the specific actions happen in the video"]},{"cell_type":"code","source":["from PIL import Image\n","\n","canvas = Image.new(\"RGB\", (int(19896/3), int(25*855/3)))\n","for i in range(25):\n","  img = Image.open(f\"plots/best_batch_{i}.png\")\n","  img = img.resize((int(19896/3), int(855/3)))\n","  canvas.paste(img, (0, int(i*855/3)))\n","canvas.save(\"plots/best_batch.png\")"],"metadata":{"id":"EnTNSE1kmgfm"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["KPRtwE4lrIkd","Sd6qb-wOrLUu","Vyk4IRlWrQBs"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}