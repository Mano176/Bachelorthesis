{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCAFA7t2gQ2OyHS4jtF4n1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wi6g6qlWz2wV"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd \"drive/MyDrive/OwnProcedure\""]},{"cell_type":"code","source":["dataset_length = 1000\n","path = \"./dataset\"\n","generator_path = \"./dataset_generator\"\n","items_path = generator_path+\"/items\"\n","backgrounds_path = generator_path+\"/backgrounds\"\n","crafting_field_coords = [(392, 72), (464, 72), (392, 144), (464, 144)]\n","prompt = \"Pick up the {dragged_obj}.\"\n","items = [\"oak_planks.png\", \"grass_block.png\", \"cobblestone.png\"]\n","items_per_obs = 3\n","slot_width = 64\n","slot_height = 64\n","cursor_x = 352\n","cursor_y = 332\n","inv_x = 928\n","inv_y = 376\n","output_width = 640\n","output_height = 360"],"metadata":{"id":"MT76gNOL0RPz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import random\n","from PIL import Image"],"metadata":{"id":"JCnflEDS2TKT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists(path):\n","  os.makedirs(path)"],"metadata":{"id":"AGF8_Ch-2L4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def img_to_mask(img):\n","  return Image.fromarray(np.uint8((img[:, :, 3] > 0)*255))"],"metadata":{"id":"Lj6D6KSx3168"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(generator_path+\"/inventory.txt\") as f:\n","  coords = [(int(x), int(y)) for x, y in [coord.replace(\"\\n\", \"\").split() for coord in f.readlines()]]\n","\n","imgs = []\n","masks = []\n","backgrounds = []\n","for item in items:\n","  img = np.array(Image.open(items_path+\"/\"+item).convert(\"RGBA\").resize((slot_width, slot_height), Image.Resampling.NEAREST))\n","  mask = img_to_mask(img)\n","  imgs.append(Image.fromarray(img))\n","  masks.append(mask)\n","inventory = Image.open(generator_path+\"/inventory.png\").convert(\"RGBA\")\n","inventory_mask = img_to_mask(np.array(inventory))\n","cursor = Image.open(generator_path+\"/cursor.png\").convert(\"RGBA\")\n","cursor_mask = img_to_mask(np.array(cursor))\n","for background_file in os.listdir(backgrounds_path):\n","  backgrounds.append(Image.open(backgrounds_path+\"/\"+background_file).convert(\"RGB\"))"],"metadata":{"id":"_MvnVg0L5hm_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(dataset_length):\n","  if (i+1)%100 == 0:\n","    print(f\"generated batch {i+1-100} - {i+1}\")\n","  folder_path = path+\"/\"+str(i+1).zfill(12)\n","  if not os.path.exists(folder_path):\n","    os.makedirs(folder_path)\n","  indeces = random.sample(range(items_per_obs), items_per_obs)\n","  first_index = indeces[0]\n","  prompt_asset = imgs[first_index]\n","  prompt_asset_segm = masks[first_index]\n","  with open(f\"{folder_path}/prompt.txt\", \"w\") as f:\n","    f.write(prompt)\n","  prompt_asset.save(f\"{folder_path}/asset.png\")\n","  prompt_asset_segm.save(f\"{folder_path}/asset_segm.png\")\n","\n","  rand_coords = random.sample(coords, items_per_obs)\n","  inv = inventory.copy()\n","  for i, (x, y) in enumerate(rand_coords):\n","    inv.paste(imgs[indeces[i]], (x, y), masks[indeces[i]])\n","  inv.paste(cursor, (cursor_x, cursor_y), cursor_mask)\n","  obs = random.sample(backgrounds, 1)[0]\n","  obs.paste(inv, (inv_x, inv_y), inventory_mask)\n","  obs = obs.resize((output_width, output_height))\n","  obs.save(f\"{folder_path}/obs.png\")\n","\n","  target_x, target_y = rand_coords[0]\n","  target_x = (target_x+slot_width/2)/inventory.width*100\n","  target_y = (target_y+slot_height/2)/inventory.height*100\n","\n","  with open(f\"{folder_path}/actions.txt\", \"w\") as f:\n","    f.write(f\"{target_x} {target_y} {1} {0} {0} {0}\")"],"metadata":{"id":"O0fmnAr72igJ"},"execution_count":null,"outputs":[]}]}